Tensor Algebra Programming Language (TAProL) Specification
AUTHOR: Dmitry I. Lyakh (Liakh): quant4me@gmail.com, liakhdi@ornl.gov
REVISION: 2019/02/16

Copyright (C) 2016-2019 Dmitry I. Liakh.
Copyright (C) 2016-2019 Oak Ridge National Laboratory, UT-Battelle, LLC.


0. PREAMBULE

TAProL is a high-level concise programming language for expressing numerical tensor algebra
computations, that is, numerical operations performed on individual tensors and their aggregates.
A subset of TAProL also serves as the assembly language for the ExaTENSOR tensor algebra processor.


1. TAProL PROGRAM STRUCTURE

A TAProl program, written in one or more source files with extension .tapl, is a collection
of "Scopes" with a single "Entry Point". The Entry Point specifies the first Scope to interpret.
Each Scope contains TAProl code. A Scope can call another Scope which will return to the
next line after finishing. By default, the objects defined within a specfic Scope are only
visible to that Scope. To pass objects from one Scope to another Scope the "Exchange Space"
has to be used. The Exchange Space contains named objects for exchange between Scopes,
together with their access permissions. An object can be Exported from one Scope into the
Exchange Space with user-defined access permissions and subsequently Imported by another Scope,
provided that the latter has matching access permissions. Thus, different Scopes may depend
on each other only via data dependencies mediated through the Exchange Space.

In the following text, names in angle brackets <> are supposed to be substituted by
the corresponding content. A list of keywords separated by "|" within a pair of curly
brackets {} provides alternatives among which a specific one needs to be chosen by
the programmer. All user-defined names in TAProl are case-sensitive and may only contain
alphanumeric characters and underscores "_", and must begin with a letter character.

Scope specification:

 scope <scope_name> group(<group_name>,<group_name>,...)
  <TAProl_code>
 end scope <scope_name>

 The comma-separated list of <group_name> specifies which logical
 groups the Scope belongs to. Each Scope always belongs to its
 default (own) group, which has the same name as the Scope, as well
 as to the global group called "GLOBAL" which contains all Scopes.
 Example:
  scope my_scope group()
  end scope my_scope
 Example:
  scope my_scope group(DMRG,CC)
  end scope my_scope

Entry Point specification:
 entry: <scope_name>

 The Entry Point must be specified before any Scope and it must appear only once,
 specifically in the source file containing the Scope referred to.


2. TAProl LANGUAGE CONSTRUCTS

2.1. Basic declarations:

Vector space specification:

 space({real|complex}): <space0_name> = <range0>, <space1_name> = <range1>, ...

 where
  {real|complex} is the selector between the Real or Complex number fields;
  <rangeX> is the dimension of the vector space <spaceX_name> in the form [<first>:<last>],
  where
   <first> and <last> define the numeration of the basis vectors, and the actual
   dimension of the space is (<last>-<first>+1). <first> and <last> can either
   be numerical literals or alphanumeric identifiers (with at least one letter).
   In both cases, their actual values must be non-negative and the upper limit
   must be no less than the lower limit.  If used, the alphanumeric identifiers
   will be dereferenced from the Exchange Space, assuming that they are available
   there (if not, the program will fail).
 Example:
  space(complex): space1=[0:947], space2=[1:upper_limit2]
 Here "upper_limit2" will be looked up in the Exchange Space.

Vector subspace specification:

 subspace(<space_name>): <subspace0_name> = <range0>, <subspace1_name> = <range1>, ...

 where
  <space_name> is the name of the parental vector space defined by the "space" statement before;
  <rangeX> is the subrange of basis vectors which define the subspace being declared in
  the form [<first>:<last>], analogously with the above description of the "space" statement.
  The subrange must be contained within the range used in the parental vector space definition.
 Example:
  space(real): space1=[0:947]
  subspace(space1): subspace0=[13:134], subspace1=[lower1:upper1]
 Here, again, "lower1" and "upper1" identifiers will be looked up in the Exchange Space.

 Each declared vector space automatically declares itself as a subspace under the same name.

Index specification (placeholder for a given subspace):

 index(<subspace_name>): <index_name>,<index_name>, ...

 where
  <subspace_name> is the name of a subspace, either defined automatically by the
  vector space declaration or defined explicitly via the "subspace" statement.
  Each index defined in this way is associated with the subspace <subspace_name>.
 Example:
  space(real): space1=[0:947]
  subspace(space1): subspace0=[13:134], subspace1=[lower1:upper1]
  index(space1): p,q1
  index(subspace0): i,j,k,l1
  index(subspace1): a1,b1,c2,d

Index inheritance:

 index: <index_name1>=<index_name0>,<index_name3>=<index_name2>, ...

 where
  index <index_name1> inherits the properies from an already defined index <index_name0>, etc.
 Example:
  index: b1=a1, b2=a2
 Here indices b1 and b2 will bind to the same subspaces as a1 and a2, respectively.


2.2. Tensor creation and destruction:

A tensor can be defined in two ways. First, it can be defined via its alphanumeric name (at least one letter)
and a comma-separated list of indices enclosed in parentheses: <tensor_name>(<index>,<index>,...).
No space is allowed between the tensor name and the left parenthesis. A scalar (order-0) tensor can be defined
as <scalar_name>(). Each index in the tensor declaration associates its subspace with the corresponding
tensor dimension. The total number of tensor dimensions (total number of tensor indices) is called
the tensor order (or the tensor rank). The subspace associated with a specific tensor dimension determines
the range of that tensor dimension; the dimension of the subspace determines the extent of the tensor dimension.
Alternatively, a tensor can be defined via its alphanumeric name (at least one letter) and a comma-separated
list of integer pairs: <tensor_name>(<lower_bound1>:<upper_bound1>,<lower_bound2:upper_bound2>,...). In this
case, the range of each tensor dimension is defined explicitly via integer literals (bounds), with the same
restrictions as used in the space/subspace declarations. All such literal ranges refer to the same unnamed
vector space of infinite dimension. A mixed definition of tensors is also allowed, where some tensor dimensions
are defined via symbolic indices and some via explicit literal ranges. All tensors with the same name are
considered as part of the same (super-)tensor.

Examples of tensors: S34(a1,b,c3), TT(i,j,k,l), SS1(), B5(10:34,45:63), CR23(i,0:15,lw3:up3,45:134).
In the last tensor, lw3 and up3 are previously defined identifiers looked up in the Exchange Space.

Explicit creation with initialization:

 1) <tensor> = <numerical_value>
    If <numerical_value> is a numerical literal, then all tensor elements will be assigned
    that specific numerical value. Complex numbers are specified in curly brackets {real,imag}.
    If <numerical_value> is an alphanumeric identifier, it will be dereferenced from the
    Exchange Space, provided it is there. Examples:
    T3(i1,u,w23,k) = 0.0
    D(i2,7) = {1.0,0.0}
    W2(k,l,m) = init_value1

 2) <tensor> = method("<method_name>")
    where "<method_name>" is a symbolic name of the corresponding user-defined functor
    used to initialize the tensor right after its creation. Example:
    RR(i,j,k,l,m) = method("Init_my_tensor")

 3) load <tensor>: tag("<stored_name>")
    This statement will either load a full tensor or a specific tensor slice from the
    persistent storage space where the tensor is marked by its "<stored_name>". Examples:
    load S2(i,j,k): tag("My old tensor")
    If a tensor index has already been defined, its range must match the stored value.
    If a tensor index is undefined, it will become defined from the stored value.

Explicit creation without initialization:

 <tensor> = ?

 For example: T2(a,b,c,d) = ?

Explicit creation with deferred initialization:

 <tensor> => method("<method_name>")

 The tensor is created, but its initialization by method "<method_name>" is
 postponed until it is used for the first time after its creation. Examples:
 Y12(j,m,n,k) => method("My deferred init method")

 In addition to explicit construction, a tensor will be constructed implicitly
 when it is undefined while being the result of a tensor operation.

Index symmetry restrictions (index seniority ordering):

 Optionally, one can specify index symmetry restrictions during tensor creation,
 except for the "load" statement. The index symmetry restrictions are appended
 in square brackets at the end of the creation/initalization statement after a colon,
 for example:

 T2(a,b,i,j,k) = 0: [a<=b] [i<j<k]
 MM(a,b) = 0: [a<b]

 In this case, only the tensor parts satisfying these conditions will be created.
 In particular, MM(a,b) will be created as an upper triangular matrix. Index symmetry
 restrictions can also be specified during indirect tensor creation in a tensor
 operation (when a previously undefined tensor appears as a result of the operation).

Explicit destruction:

 ~{<tensor>|<tensor_name>}

 OR

 destroy {<tensor>|<tensor_name>},{<tensor>|<tensor_name>},...

 Both forms are equivalent, except the latter can be applied to multiple tensors simultaneously.
 If a tensor is specified by its <tensor_name>, then the entire tensor will be destroyed.
 Optionally, by providing tensor indices and/or explicit ranges in <tensor>, only the specific
 slice will be destroyed. Examples:
  ~Y13
  ~T4(i,j,k)
  destroy R5
  destroy F3(m,n,k)
  destroy C4,TT(i,l,4:7)
 It is not permitted to use literal ranges for tensor dimensions created via subspace indices,
 and vice versa.

A tensor can be stored in persistent storage by the following statement:

 save <tensor>: tag("<stored_name>")

 The tag "<stored_name>" associated with the tensor in the persistent storage can
 later be used for loading it back via the "load" statement.


2.3. Tensor operations:

A tensor operation is a numerical primitive operating on tensors and/or tensor slices.
As a result of the tensor operation, some tensors may get updated (output tensors).
In general, the output tensors may be undefined beforehand, in which case they will
be created and defined as the result of the tensor operation. Each tensor in a tensor
operation may appear as complex conjugated via adding "+" right after the tensor name
prior to the left parenthesis, for example: S34+(a,b,c,d). The predefined basic tensor
operations can be specified symbolically via tensor notation, in which there is one
output tensor on the l.h.s of the expression, and no more than two input tensors
(plus some numerical literals) on the r.h.s. of the expression. In such tensor
expressions, tensor indices (if any) on the l.h.s. must be mutually distinct. These
indices are the ForAll indices, that is, the tensor expression is element-wise iterated
over all possible combinations of these indices (possibly with restrictions). All l.h.s.
indices are ForAll indices. Any of them may also appear on the r.h.s. of the tensor
expression. The tensor indices which solely appear on the r.h.s. of the tensor
expression are the Summation indices, that is, an implicit summation is run over
these indices (over their associated ranges). Consequently, each tensor expression
is element-wise iterated over the ForAll indices while a summation over the Summation
indices is performed for each allowed combination of the ForAll indices.

The TAProL programming language also defines composite tensor operations, in which
more than one output tensor may appear on the l.h.s. and more than two input tensors
may appear on the r.h.s. of the corresponding tensor expression. The precise rules
are further clarified in the specification of such tensor operations.

Examples of defined basic tensor operations:

 1) Assignment:
    <tensor> = <numerical_value>
    <tensor> = method("<method_name>")
    Examples:
    T1(i,j,k,l) = 0
    T1(i,j,k,l) = new_value
    T1(i,j,k,l) = method("Init my tensor")
    In the second example, "new_value" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once.

 2) Permutation of tensor dimensions (including the trivial copy case):
    <tensor0> = <tensor1>
    Examples:
    T1(i,j,k,l) = S1(i,j,k,l)
    T1(i,j,k,l) = S1(k,j,l,i)
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right only once.

 3) Scalar scaling:
    <tensor> *= <numerical_value>
    Examples:
    T1(i,j,k,l) *= 1.13
    T1(i,j,k,l) *= my_factor
    In the second example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once.

 4) Basic folding (dimension flattening):
    <tensor0> = <tensor1>
    Examples:
    S1(a,k) = T1(i,j,k,l)
    Here dimensions i, j, l of T1 will be combined into dimension a=(i,j,l) of S1.
    The combined (i,j,l) range must have the same extent as the range of (a).
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the right of "=" must appear only once;
                          (3) There must be only one index that appears on the left but not on the right;
                          (4) There must be at least two indices on the right that do not appear on the left.

 5) Basic unfolding (dimension expansion):
    <tensor0> = <tensor1>
    Examples:
    T1(i,j,k,l) = S1(a,k)
    Here dimension a of S1 is unfolded into three dimensions of T1, namely, (i,j,l).
    The combined (i,j,l) range must have the same extent as the range of (a).
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the right of "=" must appear only once;
                          (3) There must be only one index that appears on the right but not on the left;
                          (4) There must be at least two indices on the left that do not appear on the right.

 6) Addition:
    <tensor0> += <tensor1> {|* <numerical_value>}
    Examples:
    T1(i,j,k,l) += S1(j,k,i,l)
    T1(i,j,k,l) += S1(i,j,k,l) * -1.13
    T1(i,j,k,l) += S1(j,k,i,l) * my_factor
    In the third example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right only once.

 7) Direct product:
    <tensor0> += <tensor1> * <tensor2> {|* <numerical_value>}
    where <tensor1> and <tensor2> do not have indices in common.
    Examples:
    T1(i,j,k,l) += S1(k,j) * S2(i,l)
    T1(i,j,k,l) += S1(i,j) * S2(k,l) * -1.13
    T1(i,j,k,l) += S1(k,j) * S2(i,l) * my_factor
    In the third example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right only once.

 8) Hadamard product:
    <tensor0> += <tensor1> * <tensor2> {|* <numerical_value>}
    where <tensor0>, <tensor1>, and <tensor2> all consist of the same indices.
    Examples:
    H1(a,b,c) += L3(b,a,c) * R3(c,b,a)
    H1(a,b,c) += L3(a,b,c) * R3(a,b,c) * {54.13,-1.45}
    H1(a,b,c) += L3(b,a,c) * R3(a,b,c) * my_factor
    In the third example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right,
                              exactly once in each r.h.s. tensor argument.

 9) Khatri-Rao product (and generalizations):
    <tensor0> += <tensor1> * <tensor2> {|* <numerical_value>}
    Examples:
    H1(a,b,c) += L5(a,c) * Y1(c,b)
    G3(a,b,c,d) += Q(d,b,a) * R(a,c) * {1.0,5.0}
    G3(a,b,c,d) += Q(d,b,a) * R(a,c) * my_factor
    In the third example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right.

 10) Binary contraction:
    <tensor0> += <tensor1> * <tensor2> {|* <numerical_value>}
    where <tensor1> and <tensor2> have Summation indices in common (contracted indices).
    Examples:
    T1(i,j,k,l) += S1(k,c,j,d) * S2(c,i,l,d)
    T1(i,j,k,l) += S1(k,c,j,d) * S2(d,i,c,l) * -1.13
    T1(i,j,k,l) += S1(k,c,j,d) * S2(c,i,l,d) * my_factor
    In the third example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right only once;
                          (3) Every index on the right, which is not present on the left, must appear
                              twice on the right in different r.h.s. tensors.

 11) Partial or full trace (and generalizations):
    <tensor0> += <tensor1> {|* <numerical_value>}
    where <tensor1> has repeated indices.
    Examples:
    T3(a) += Y7(c,a,c) * -2.73
    X6() += C2(b,b)
    U2(c,d) += W2(a,c,a,d,a) * {-5.43,0.0}
    U2(c,d) += W2(a,d,a,c,a) * my_factor
    In the third example, "my_factor" will be looked up in the Exchange Space, if there.
    Pattern restrictions: (1) Every index on the left of "=" must appear only once;
                          (2) Every index on the left of "=" must also appear on the right only once;
                          (3) Every index on the right, which is not present on the left, must appear
                              at least twice on the right.


2.4. Tensor network specification:

A tensor network is a contraction of two or more tensors. It can be specified as (example):
 TN(i,j,k,l) => F1(i,a) * F2(a,j,b) * F3(b,k,c) * F4(c,l)
Here TN(i,j,k,l) is just a placeholder for the 4-tensor contraction defined on the r.h.s.
Whenever TN(i,j,k,l) is encountered in a tensor expression, it will be expanded accordingly.

A tensor network specification can be used for defining tensor decompositions, for example:
 TN(i,j,k,l) = S13(i,j,k,l)
where TN(i,j,k,l) is a tensor network placeholder, for instance the one defined above.
This statement will factorize the tensor S13(i,j,k,l) according to the structure of TN(i,j,k,l).

Another example (SVD decomposition in TAProL):
 TN(i,j,k,l) => F1(i,j,d) * S(d) * F2(d,k,l)
 TN(i,j,k,l) = S13(i,j,k,l)
 F1+(i,j,c) * F1(i,j,d) = DELTA(c,d)
 F2+(c,k,l) * F2(d,k,l) = DELTA(c,d)
Here the tensor S13(i,j,k,l) will be decomposed into F1(i,j,d) * S(d) * F2(d,k,l).


2.5. Passing control to other Scopes and data exchange between Scopes:

A Scope can be invoked from another Scope by the following statement:

 invoke <scope_name>

After finishing, the invoked Scope will pass control back to the
statement following "invoke ...".

To pass data between Scopes, the following statements are used:

 export <tensor>: tag("<external_tag>") to(<group_name>:<access>,<group_name>:<access>,...)

This will expose a tensor (or a tensor slice) <tensor> to the Exchange Space
under a unique name <external_tag>. All Scopes belonging to either group from
the comma-separated list will be able to access the tensor via the "import" statement:

 import <tensor>: tag("<external_tag>")

The "import" statement is semantically equivalent to the "load" statement,
except that "import" only associates the data between different Scopes whereas
"load" actually loads the data from the persistent storage.
<access> parameters in the "export" statement regulate the access permissions for each
group the tensor is exported to, taking the following possible values:
 "r" which means Read Only;
 "w" which means Read-or-Write;


2.6. External application-defined data and tensor methods:

In most cases the application will need to provide some domain data for tensor initialization
and/or processing as well as define some external tensor operations peculiar to a specific domain.
A compliant TAProL server must provide two relevant registration API functions:

 taprolDataRegister(name_identifier:string, location_identifier:TensorData)

 taprolMethodRegister(name_identifier:string, functor_identifier:TensorMethod*)

The <name_identifier> is an alphanumeric_ name associated with the data or method that can later
appear in TAProL statements. The data <location_identifier> contains information necessary for
locating the exposed data, for example the base pointer and the size. The <functor_identifier>
is a pointer to a concrete implementation of the TensorMethod interface. The TensorMethod interface
exposes a deferred member function .apply(const LocalTensor &), where LocalTensor is a descriptor
of a locally stored tensor, which encompasses tensor signature (name, id), tensor shape, and tensor
body location (base pointer and size where the local tensor data is stored). By overriding this
deferred member function, the concrete implementations of the TensorMethod interface, defined in
the application, can supply user-defined tensor operations into the TAProL code.
